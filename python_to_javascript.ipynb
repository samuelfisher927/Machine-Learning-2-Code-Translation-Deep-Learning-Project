{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load Data",
   "id": "9481b901d6dce198"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:27:02.648531Z",
     "start_time": "2025-05-25T05:27:02.645832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(\"data/generation/pair_data_tok_1/Python-Javascript\")\n",
    "TRAIN_SRC = BASE_DIR / \"train-Python-Javascript-tok.py\"\n",
    "TRAIN_TGT = BASE_DIR / \"train-Python-Javascript-tok.js\"\n",
    "TRAIN_SRC_MAP = BASE_DIR / \"train-Python-map.jsonl\"\n",
    "TRAIN_TGT_MAP = BASE_DIR / \"train-Javascript-map.jsonl\"\n",
    "\n",
    "VAL_SRC = BASE_DIR / \"val-Python-Javascript-tok.py\"\n",
    "VAL_TGT = BASE_DIR / \"val-Python-Javascript-tok.js\"\n",
    "VAL_SRC_MAP = BASE_DIR / \"val-Python-map.jsonl\"\n",
    "VAL_TGT_MAP = BASE_DIR / \"val-Javascript-map.jsonl\""
   ],
   "id": "fa48fc4d7d731028",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:27:30.600975Z",
     "start_time": "2025-05-25T05:27:30.557538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_pairs(src_file, tgt_file, src_map_file, tgt_map_file):\n",
    "    src_lines = [ln.strip() for ln in open(src_file, encoding=\"utf-8\") if ln.strip()]\n",
    "    tgt_lines = [ln.strip() for ln in open(tgt_file, encoding=\"utf-8\") if ln.strip()]\n",
    "    # maps are one-to-one but not used for modeling; kept for reference\n",
    "    src_ids = [ln.strip() for ln in open(src_map_file, encoding=\"utf-8\")]\n",
    "    tgt_ids = [ln.strip() for ln in open(tgt_map_file, encoding=\"utf-8\")]\n",
    "    assert len(src_lines) == len(tgt_lines)\n",
    "    return list(zip(src_lines, tgt_lines))\n",
    "\n",
    "train_pairs = load_pairs(TRAIN_SRC, TRAIN_TGT, TRAIN_SRC_MAP, TRAIN_TGT_MAP)\n",
    "val_pairs = load_pairs(VAL_SRC, VAL_TGT, VAL_SRC_MAP, VAL_TGT_MAP)"
   ],
   "id": "4f654cb0505af0d9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:28:34.037356Z",
     "start_time": "2025-05-25T05:28:32.449329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CodeTranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, tokenizer, max_len=256):\n",
    "        self.pairs = pairs\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.pairs[idx]\n",
    "        enc = self.tokenizer(src, truncation=True,\n",
    "                             padding=\"max_length\",\n",
    "                             max_length=self.max_len,\n",
    "                             return_tensors=\"pt\")\n",
    "        dec = self.tokenizer(tgt, truncation=True,\n",
    "                             padding=\"max_length\",\n",
    "                             max_length=self.max_len,\n",
    "                             return_tensors=\"pt\")\n",
    "        input_ids = enc.input_ids.squeeze()\n",
    "        attn_mask = enc.attention_mask.squeeze()\n",
    "        labels = dec.input_ids.squeeze()\n",
    "        # replace pad token id in labels by -100 for CE ignore\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attn_mask,\n",
    "            \"labels\": labels\n",
    "        }\n"
   ],
   "id": "8bca7e40d5236a80",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:28:41.633445Z",
     "start_time": "2025-05-25T05:28:39.460370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codet5-small\")\n",
    "# ensure padding token exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "train_ds = CodeTranslationDataset(train_pairs, tokenizer)\n",
    "val_ds = CodeTranslationDataset(val_pairs, tokenizer)"
   ],
   "id": "fd9651ac2688353b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4089b0b268844ae0a11556fd7ed74288"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1e6d55583324e78bc27e51ed99eab04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a85b7b4fb4cf4612805bdceeb18eaa85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d59edfbb73b49ebb81d3df9d62c0bf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ebf192cc8ca425f9b9b9d63b86927d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:30:24.088453Z",
     "start_time": "2025-05-25T05:30:24.085415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 7 — DataLoaders\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n"
   ],
   "id": "c334c74df5ad67b6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline Pretrained Transformer",
   "id": "c71f8762250ec28f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T05:29:44.109629Z",
     "start_time": "2025-05-25T05:29:36.871360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "LR = 5e-5\n",
    "EPOCHS = 3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Salesforce/codet5-small\")\n",
    "model.resize_token_embeddings(len(tokenizer))  # in case we added PAD\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n"
   ],
   "id": "227da16fce591a67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 00:29:38.417540: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-25 00:29:38.591443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748150978.654669   85444 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748150978.673894   85444 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748150978.820336   85444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748150978.820385   85444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748150978.820386   85444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748150978.820387   85444 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-25 00:29:38.837209: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f94462aa7c14c01b7e254017c082763"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70c8d6599d7e479098a26f7e2e2faa6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a51e3d7ccba948a398077673142430b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train",
   "id": "efe705b110aceb6f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T06:12:38.060969Z",
     "start_time": "2025-05-25T05:39:45.828927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 8 — Training Loop with tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # —— Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [train]\")\n",
    "    for batch in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids      = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels         = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        avg_train = train_loss / (train_bar.n + 1)\n",
    "        train_bar.set_postfix(loss=f\"{avg_train:.4f}\")\n",
    "\n",
    "    # —— Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [val] \")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            input_ids      = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels         = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            avg_val = val_loss / (val_bar.n + 1)\n",
    "            val_bar.set_postfix(val_loss=f\"{avg_val:.4f}\")\n"
   ],
   "id": "93f23394b257419d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [train]: 100%|██████████| 8403/8403 [10:37<00:00, 13.18it/s, loss=0.2078]\n",
      "Epoch 1/3 [val] : 100%|██████████| 469/469 [00:15<00:00, 30.34it/s, val_loss=0.2094]\n",
      "Epoch 2/3 [train]: 100%|██████████| 8403/8403 [10:42<00:00, 13.08it/s, loss=0.1815]\n",
      "Epoch 2/3 [val] : 100%|██████████| 469/469 [00:15<00:00, 30.33it/s, val_loss=0.1996]\n",
      "Epoch 3/3 [train]: 100%|██████████| 8403/8403 [10:45<00:00, 13.02it/s, loss=0.1647]\n",
      "Epoch 3/3 [val] : 100%|██████████| 469/469 [00:15<00:00, 30.06it/s, val_loss=0.1935]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T06:12:45.142855Z",
     "start_time": "2025-05-25T06:12:44.857422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"codet5-python-to-js\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ],
   "id": "444feb49fba9b9a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to codet5-python-to-js\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T06:15:43.729850Z",
     "start_time": "2025-05-25T06:15:43.565150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "example_py = \"\"\"\n",
    "def debug(x: int):\n",
    "    print(\"Printing: \", x):\n",
    "\"\"\"\n",
    "inputs = tokenizer(example_py, return_tensors=\"pt\").to(DEVICE)\n",
    "gen = model.generate(**inputs, max_length=64)\n",
    "print(\"JS translation:\\n\", tokenizer.decode(gen[0], skip_special_tokens=True))"
   ],
   "id": "165c953c7ea51c71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS translation:\n",
      " function debug ( x ) { document . write ( \" \" + x ) ; }\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline Untrained Transformer",
   "id": "223314099a97fb87"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T06:21:30.256718Z",
     "start_time": "2025-05-25T06:21:28.695669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 7 — Build a BERT-style encoder–decoder from scratch\n",
    "from transformers import BertConfig, EncoderDecoderConfig, EncoderDecoderModel\n",
    "\n",
    "# 1) Encoder configuration\n",
    "encoder_cfg = BertConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=2048,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# 2) Decoder configuration (enable cross-attention & decoder mode)\n",
    "decoder_cfg = BertConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=512,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=2048,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    is_decoder=True,\n",
    "    add_cross_attention=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# 3) Combine into an EncoderDecoderConfig\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "    encoder_cfg,\n",
    "    decoder_cfg,\n",
    ")\n",
    "\n",
    "# … after EncoderDecoderConfig.from_encoder_decoder_configs(...)\n",
    "config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "config.eos_token_id           = tokenizer.sep_token_id\n",
    "config.pad_token_id           = tokenizer.pad_token_id\n",
    "\n",
    "model = EncoderDecoderModel(config)\n",
    "model.to(DEVICE)\n",
    "\n",
    "\n",
    "# 5) Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n"
   ],
   "id": "703a8a72760c9caa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T08:45:29.455732Z",
     "start_time": "2025-05-25T07:00:35.763258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS * 3):\n",
    "    # —— Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [train]\")\n",
    "    for batch in train_bar:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids      = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels         = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        avg_train = train_loss / (train_bar.n + 1)\n",
    "        train_bar.set_postfix(loss=f\"{avg_train:.4f}\")\n",
    "\n",
    "    # —— Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [val] \")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_bar:\n",
    "            input_ids      = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels         = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            avg_val = val_loss / (val_bar.n + 1)\n",
    "            val_bar.set_postfix(val_loss=f\"{avg_val:.4f}\")"
   ],
   "id": "cacc3689c114e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [train]:   0%|          | 0/8403 [00:00<?, ?it/s]/home/ubuntu/.virtualenvs/pytorch/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:631: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/home/ubuntu/.virtualenvs/pytorch/lib/python3.12/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:651: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Epoch 1/3 [train]: 100%|██████████| 8403/8403 [11:22<00:00, 12.31it/s, loss=0.3432]\n",
      "Epoch 1/3 [val] : 100%|██████████| 469/469 [00:18<00:00, 24.78it/s, val_loss=0.4209]\n",
      "Epoch 2/3 [train]: 100%|██████████| 8403/8403 [11:12<00:00, 12.49it/s, loss=0.2897]\n",
      "Epoch 2/3 [val] : 100%|██████████| 469/469 [00:18<00:00, 24.69it/s, val_loss=0.3916]\n",
      "Epoch 3/3 [train]: 100%|██████████| 8403/8403 [11:14<00:00, 12.46it/s, loss=0.2509]\n",
      "Epoch 3/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.57it/s, val_loss=0.3889]\n",
      "Epoch 4/3 [train]: 100%|██████████| 8403/8403 [11:16<00:00, 12.42it/s, loss=0.2220]\n",
      "Epoch 4/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.45it/s, val_loss=0.3795]\n",
      "Epoch 5/3 [train]: 100%|██████████| 8403/8403 [11:19<00:00, 12.37it/s, loss=0.1987]\n",
      "Epoch 5/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.27it/s, val_loss=0.3741]\n",
      "Epoch 6/3 [train]: 100%|██████████| 8403/8403 [11:20<00:00, 12.34it/s, loss=0.1791]\n",
      "Epoch 6/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.20it/s, val_loss=0.3591]\n",
      "Epoch 7/3 [train]: 100%|██████████| 8403/8403 [11:22<00:00, 12.30it/s, loss=0.1627]\n",
      "Epoch 7/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.07it/s, val_loss=0.3733]\n",
      "Epoch 8/3 [train]: 100%|██████████| 8403/8403 [11:24<00:00, 12.27it/s, loss=0.1473]\n",
      "Epoch 8/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 24.05it/s, val_loss=0.3719]\n",
      "Epoch 9/3 [train]: 100%|██████████| 8403/8403 [11:26<00:00, 12.25it/s, loss=0.1353]\n",
      "Epoch 9/3 [val] : 100%|██████████| 469/469 [00:19<00:00, 23.91it/s, val_loss=0.3710]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T14:46:01.236905Z",
     "start_time": "2025-05-25T14:46:00.859674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"bert-python-to-js_2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model saved to {output_dir}\")"
   ],
   "id": "3f0e4e1fa8e8bb76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bert-python-to-js_2\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T14:47:29.485218Z",
     "start_time": "2025-05-25T14:47:29.302348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model.eval()\n",
    "example_py = \"def debug(x): print(x)\"\n",
    "inputs = tokenizer(example_py, return_tensors=\"pt\").to(DEVICE)\n",
    "gen = model.generate(**inputs, max_length=64)\n",
    "print(\"JS translation:\\n\", tokenizer.decode(gen[0], skip_special_tokens=True))"
   ],
   "id": "c52a97939b21b3c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JS translation:\n",
      " function panx(1 ) { let temx = 0 ; let temx = 0 ; let m = 0 ; for ( let i = 0 ; i < n ; i ++ ) { temx = m ; } document . write ( temx + \" \" + temx + \" \" ) ;\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3fe19cb4d75c1b09"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
