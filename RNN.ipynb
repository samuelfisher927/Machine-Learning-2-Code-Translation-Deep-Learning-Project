{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RNN"
      ],
      "metadata": {
        "id": "ELzXHi22SMQ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6LHDjU4FRJ1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import re\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "df = pd.read_csv('python_to_valid_cpp.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocesing"
      ],
      "metadata": {
        "id": "G_icTvzJRagn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPECIAL_TOKENS = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
        "\n",
        "def tokenize_code(code):\n",
        "    return re.findall(r\"[\\w]+|[^\\s\\w]\", code)\n",
        "\n",
        "def build_vocab(token_lists, max_vocab_size=10000):\n",
        "    all_tokens = list(chain.from_iterable(token_lists))\n",
        "    token_counts = Counter(all_tokens)\n",
        "    most_common = token_counts.most_common(max_vocab_size - len(SPECIAL_TOKENS))\n",
        "    vocab = SPECIAL_TOKENS + [token for token, _ in most_common]\n",
        "    token_to_id = {token: idx for idx, token in enumerate(vocab)}\n",
        "    id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "    return token_to_id, id_to_token\n",
        "\n",
        "def tokens_to_ids(tokens, token_to_id, add_sos=False, add_eos=False):\n",
        "    ids = [token_to_id.get(token, token_to_id['<unk>']) for token in tokens]\n",
        "    if add_sos:\n",
        "        ids = [token_to_id['<sos>']] + ids\n",
        "    if add_eos:\n",
        "        ids += [token_to_id['<eos>']]\n",
        "    return ids"
      ],
      "metadata": {
        "id": "AhbAKXKWRX8Y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Dataloader"
      ],
      "metadata": {
        "id": "2dmgP3pjRePY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeTranslationDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encoder_inputs = df['py_tensor'].tolist()\n",
        "        self.decoder_inputs = df['cpp_in_tensor'].tolist()\n",
        "        self.decoder_outputs = df['cpp_out_tensor'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoder_inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoder_inputs[idx], self.decoder_inputs[idx], self.decoder_outputs[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    enc_inputs, dec_inputs, dec_outputs = zip(*batch)\n",
        "    enc_inputs_pad = pad_sequence(enc_inputs, batch_first=True, padding_value=py_token_to_id['<pad>'])\n",
        "    dec_inputs_pad = pad_sequence(dec_inputs, batch_first=True, padding_value=cpp_token_to_id['<pad>'])\n",
        "    dec_outputs_pad = pad_sequence(dec_outputs, batch_first=True, padding_value=cpp_token_to_id['<pad>'])\n",
        "    return enc_inputs_pad, dec_inputs_pad, dec_outputs_pad"
      ],
      "metadata": {
        "id": "nOaRdXRwRhf0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention-based Model"
      ],
      "metadata": {
        "id": "u6CZF85rRmZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hid_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = torch.sum(self.v * energy, dim=2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(hid_dim + emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attn = Attention(hid_dim)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attn(hidden.squeeze(0), encoder_outputs).unsqueeze(1)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, hidden = self.gru(rnn_input, hidden)\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(1), weighted.squeeze(1)), dim=1))\n",
        "        return prediction, hidden\n",
        "\n",
        "class AttnEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.gru(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "class AttnSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.embedding.num_embeddings\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        input = trg[:, 0]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "ZgQdgcgBRlpT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup"
      ],
      "metadata": {
        "id": "Fo8y0pgtUOvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg_in, trg_out in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        src, trg_in, trg_out = src.to(DEVICE), trg_in.to(DEVICE), trg_out.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg_in)\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg_out = trg_out[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, trg_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        torch.cuda.empty_cache()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg_in, trg_out in dataloader:\n",
        "            src, trg_in, trg_out = src.to(DEVICE), trg_in.to(DEVICE), trg_out.to(DEVICE)\n",
        "            output = model(src, trg_in)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_out = trg_out[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg_out)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "aVDfqN72UZwQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beam Search & BLEU"
      ],
      "metadata": {
        "id": "uGRFFuShZseB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search(model, src_tensor, beam_width=3, max_len=300):\n",
        "    model.eval()\n",
        "    src_tensor = src_tensor.unsqueeze(0).to(DEVICE)\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "    sequences = [[[], 0.0, torch.tensor([cpp_token_to_id['<sos>']], device=DEVICE), hidden]]\n",
        "    for _ in range(max_len):\n",
        "        all_candidates = []\n",
        "        for seq, score, last_token, hidden in sequences:\n",
        "            with torch.no_grad():\n",
        "                output, hidden = model.decoder(last_token, hidden, encoder_outputs)\n",
        "            probs = torch.log_softmax(output, dim=1)\n",
        "            topk = torch.topk(probs, beam_width)\n",
        "            for i in range(beam_width):\n",
        "                token = topk.indices[0][i]\n",
        "                prob = topk.values[0][i].item()\n",
        "                candidate = [seq + [token.item()], score + prob, token.unsqueeze(0), hidden]\n",
        "                all_candidates.append(candidate)\n",
        "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "        if all(seq[0][-1] == cpp_token_to_id['<eos>'] for seq in sequences):\n",
        "            break\n",
        "    return [cpp_id_to_token.get(idx, '<unk>') for idx in sequences[0][0] if idx != cpp_token_to_id['<eos>']]\n",
        "\n",
        "def compute_bleu(pred_tokens, ref_tokens):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    return sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "\n",
        "def evaluate_bleu(model, val_df, num_samples=5):\n",
        "    total_bleu = 0\n",
        "    for i in range(min(num_samples, len(val_df))):\n",
        "        row = val_df.iloc[i]\n",
        "        src_tensor = torch.tensor(row['py_input_ids'], dtype=torch.long)\n",
        "        pred = beam_search(model, src_tensor)\n",
        "        ref = row['cpp_tokens']\n",
        "        bleu = compute_bleu(pred, ref)\n",
        "        total_bleu += bleu\n",
        "        print(f\"Example {i+1} BLEU: {bleu:.4f}\")\n",
        "    avg_bleu = total_bleu / num_samples\n",
        "    print(f\"\\nAvg BLEU over {num_samples} samples: {avg_bleu:.4f}\")\n",
        "    return avg_bleu\n",
        "\n",
        "def save_model(model, path=\"best_model.pt\"):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(model, path=\"best_model.pt\"):\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.eval()"
      ],
      "metadata": {
        "id": "960B8g9MUZ6i"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "S96f5w3vaB_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"python_to_valid_cpp.csv\")\n",
        "\n",
        "df['py_tokens'] = df['code'].apply(tokenize_code)\n",
        "df['cpp_tokens'] = df['cpp_code'].apply(tokenize_code)\n",
        "\n",
        "py_token_to_id, py_id_to_token = build_vocab(df['py_tokens'])\n",
        "cpp_token_to_id, cpp_id_to_token = build_vocab(df['cpp_tokens'])\n",
        "\n",
        "df['py_input_ids'] = df['py_tokens'].apply(lambda tokens: tokens_to_ids(tokens, py_token_to_id))\n",
        "df['cpp_input_ids'] = df['cpp_tokens'].apply(lambda tokens: tokens_to_ids(tokens, cpp_token_to_id, add_sos=True))\n",
        "df['cpp_output_ids'] = df['cpp_tokens'].apply(lambda tokens: tokens_to_ids(tokens, cpp_token_to_id, add_eos=True))\n",
        "\n",
        "df['py_tensor'] = df['py_input_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "df['cpp_in_tensor'] = df['cpp_input_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "df['cpp_out_tensor'] = df['cpp_output_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "\n",
        "MAX_LEN = 300\n",
        "df = df[df['py_input_ids'].apply(len) <= MAX_LEN]\n",
        "df = df[df['cpp_input_ids'].apply(len) <= MAX_LEN]\n",
        "df = df[df['cpp_output_ids'].apply(len) <= MAX_LEN]\n"
      ],
      "metadata": {
        "id": "kPgME7nfaFoC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(CodeTranslationDataset(train_df), batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(CodeTranslationDataset(val_df), batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "CtF1vOI6aR9H"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INPUT_DIM = len(py_token_to_id)\n",
        "OUTPUT_DIM = len(cpp_token_to_id)\n",
        "EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "encoder = AttnEncoder(INPUT_DIM, EMB_DIM, HID_DIM).to(DEVICE)\n",
        "decoder = AttnDecoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(DEVICE)\n",
        "model = AttnSeq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=cpp_token_to_id['<pad>'])\n"
      ],
      "metadata": {
        "id": "2mg3jL8xaSHC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "GL8HjLJVb1Tw"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 30\n",
        "CLIP = 1.0\n",
        "best_bleu = 0\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "    bleu = evaluate_bleu(model, val_df, num_samples=5)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU: {bleu:.4f}\")\n",
        "\n",
        "    if bleu > best_bleu:\n",
        "        best_bleu = bleu\n",
        "        save_model(model, \"best_model.pt\")\n",
        "        print(\" Best model saved\")\n",
        "\n",
        "    early_stopper.step(val_loss)\n",
        "    if early_stopper.early_stop:\n",
        "        print(\" Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRF3PJD-aXDb",
        "outputId": "268d019b-1160-45f6-edc6-c4fede0f0f4b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.0252\n",
            "Example 2 BLEU: 0.0195\n",
            "Example 3 BLEU: 0.0089\n",
            "Example 4 BLEU: 0.0071\n",
            "Example 5 BLEU: 0.0095\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0140\n",
            "Epoch 1 | Train Loss: 4.1988 | Val Loss: 3.7532 | BLEU: 0.0140\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.0643\n",
            "Example 2 BLEU: 0.0662\n",
            "Example 3 BLEU: 0.0189\n",
            "Example 4 BLEU: 0.0909\n",
            "Example 5 BLEU: 0.0287\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0538\n",
            "Epoch 2 | Train Loss: 3.3745 | Val Loss: 3.3667 | BLEU: 0.0538\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.0747\n",
            "Example 2 BLEU: 0.0779\n",
            "Example 3 BLEU: 0.0570\n",
            "Example 4 BLEU: 0.0615\n",
            "Example 5 BLEU: 0.0388\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0620\n",
            "Epoch 3 | Train Loss: 2.8607 | Val Loss: 3.1166 | BLEU: 0.0620\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.1149\n",
            "Example 2 BLEU: 0.1021\n",
            "Example 3 BLEU: 0.0575\n",
            "Example 4 BLEU: 0.3992\n",
            "Example 5 BLEU: 0.0594\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1466\n",
            "Epoch 4 | Train Loss: 2.5055 | Val Loss: 2.8949 | BLEU: 0.1466\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.2612\n",
            "Example 2 BLEU: 0.1348\n",
            "Example 3 BLEU: 0.1025\n",
            "Example 4 BLEU: 0.4146\n",
            "Example 5 BLEU: 0.0533\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1933\n",
            "Epoch 5 | Train Loss: 2.2148 | Val Loss: 2.7866 | BLEU: 0.1933\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.1706\n",
            "Example 2 BLEU: 0.3756\n",
            "Example 3 BLEU: 0.1022\n",
            "Example 4 BLEU: 0.3694\n",
            "Example 5 BLEU: 0.0684\n",
            "\n",
            "Avg BLEU over 5 samples: 0.2172\n",
            "Epoch 6 | Train Loss: 2.0026 | Val Loss: 2.6750 | BLEU: 0.2172\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.2080\n",
            "Example 2 BLEU: 0.3667\n",
            "Example 3 BLEU: 0.1215\n",
            "Example 4 BLEU: 0.3820\n",
            "Example 5 BLEU: 0.1898\n",
            "\n",
            "Avg BLEU over 5 samples: 0.2536\n",
            "Epoch 7 | Train Loss: 1.8373 | Val Loss: 2.5011 | BLEU: 0.2536\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.3413\n",
            "Example 2 BLEU: 0.3438\n",
            "Example 3 BLEU: 0.2906\n",
            "Example 4 BLEU: 0.5048\n",
            "Example 5 BLEU: 0.1719\n",
            "\n",
            "Avg BLEU over 5 samples: 0.3305\n",
            "Epoch 8 | Train Loss: 1.6913 | Val Loss: 2.5115 | BLEU: 0.3305\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.3674\n",
            "Example 2 BLEU: 0.4085\n",
            "Example 3 BLEU: 0.3818\n",
            "Example 4 BLEU: 0.5050\n",
            "Example 5 BLEU: 0.2597\n",
            "\n",
            "Avg BLEU over 5 samples: 0.3845\n",
            "Epoch 9 | Train Loss: 1.6071 | Val Loss: 2.3815 | BLEU: 0.3845\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4738\n",
            "Example 2 BLEU: 0.4918\n",
            "Example 3 BLEU: 0.3172\n",
            "Example 4 BLEU: 0.4895\n",
            "Example 5 BLEU: 0.1749\n",
            "\n",
            "Avg BLEU over 5 samples: 0.3894\n",
            "Epoch 10 | Train Loss: 1.5095 | Val Loss: 2.3067 | BLEU: 0.3894\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4707\n",
            "Example 2 BLEU: 0.4792\n",
            "Example 3 BLEU: 0.4023\n",
            "Example 4 BLEU: 0.6541\n",
            "Example 5 BLEU: 0.3012\n",
            "\n",
            "Avg BLEU over 5 samples: 0.4615\n",
            "Epoch 11 | Train Loss: 1.4468 | Val Loss: 2.2540 | BLEU: 0.4615\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5151\n",
            "Example 2 BLEU: 0.5617\n",
            "Example 3 BLEU: 0.4563\n",
            "Example 4 BLEU: 0.6470\n",
            "Example 5 BLEU: 0.4423\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5245\n",
            "Epoch 12 | Train Loss: 1.3804 | Val Loss: 2.3051 | BLEU: 0.5245\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4302\n",
            "Example 2 BLEU: 0.7230\n",
            "Example 3 BLEU: 0.4842\n",
            "Example 4 BLEU: 0.6393\n",
            "Example 5 BLEU: 0.4341\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5422\n",
            "Epoch 13 | Train Loss: 1.3254 | Val Loss: 2.1484 | BLEU: 0.5422\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5233\n",
            "Example 2 BLEU: 0.6029\n",
            "Example 3 BLEU: 0.3759\n",
            "Example 4 BLEU: 0.5931\n",
            "Example 5 BLEU: 0.3702\n",
            "\n",
            "Avg BLEU over 5 samples: 0.4931\n",
            "Epoch 14 | Train Loss: 1.3156 | Val Loss: 2.1338 | BLEU: 0.4931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4480\n",
            "Example 2 BLEU: 0.4797\n",
            "Example 3 BLEU: 0.4130\n",
            "Example 4 BLEU: 0.7064\n",
            "Example 5 BLEU: 0.2221\n",
            "\n",
            "Avg BLEU over 5 samples: 0.4539\n",
            "Epoch 15 | Train Loss: 1.2908 | Val Loss: 2.1397 | BLEU: 0.4539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5207\n",
            "Example 2 BLEU: 0.5175\n",
            "Example 3 BLEU: 0.5042\n",
            "Example 4 BLEU: 0.8562\n",
            "Example 5 BLEU: 0.1843\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5166\n",
            "Epoch 16 | Train Loss: 1.2595 | Val Loss: 2.1922 | BLEU: 0.5166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4714\n",
            "Example 2 BLEU: 0.6701\n",
            "Example 3 BLEU: 0.4489\n",
            "Example 4 BLEU: 0.7991\n",
            "Example 5 BLEU: 0.4577\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5694\n",
            "Epoch 17 | Train Loss: 1.2866 | Val Loss: 2.2562 | BLEU: 0.5694\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4686\n",
            "Example 2 BLEU: 0.5550\n",
            "Example 3 BLEU: 0.2141\n",
            "Example 4 BLEU: 0.8036\n",
            "Example 5 BLEU: 0.3311\n",
            "\n",
            "Avg BLEU over 5 samples: 0.4745\n",
            "Epoch 18 | Train Loss: 1.2365 | Val Loss: 2.0532 | BLEU: 0.4745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5351\n",
            "Example 2 BLEU: 0.5009\n",
            "Example 3 BLEU: 0.4559\n",
            "Example 4 BLEU: 0.9086\n",
            "Example 5 BLEU: 0.5536\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5908\n",
            "Epoch 19 | Train Loss: 1.2340 | Val Loss: 2.1994 | BLEU: 0.5908\n",
            " Best model saved!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.6240\n",
            "Example 2 BLEU: 0.6504\n",
            "Example 3 BLEU: 0.2393\n",
            "Example 4 BLEU: 0.8522\n",
            "Example 5 BLEU: 0.2588\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5249\n",
            "Epoch 20 | Train Loss: 1.2207 | Val Loss: 2.2909 | BLEU: 0.5249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.6671\n",
            "Example 2 BLEU: 0.5888\n",
            "Example 3 BLEU: 0.2534\n",
            "Example 4 BLEU: 0.8508\n",
            "Example 5 BLEU: 0.3851\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5490\n",
            "Epoch 21 | Train Loss: 1.2904 | Val Loss: 2.4089 | BLEU: 0.5490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4820\n",
            "Example 2 BLEU: 0.2683\n",
            "Example 3 BLEU: 0.4793\n",
            "Example 4 BLEU: 0.7308\n",
            "Example 5 BLEU: 0.1408\n",
            "\n",
            "Avg BLEU over 5 samples: 0.4203\n",
            "Epoch 22 | Train Loss: 1.3359 | Val Loss: 2.1708 | BLEU: 0.4203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5800\n",
            "Example 2 BLEU: 0.6591\n",
            "Example 3 BLEU: 0.4852\n",
            "Example 4 BLEU: 0.7998\n",
            "Example 5 BLEU: 0.3080\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5664\n",
            "Epoch 23 | Train Loss: 1.2586 | Val Loss: 2.0495 | BLEU: 0.5664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.3947\n",
            "Example 2 BLEU: 0.5643\n",
            "Example 3 BLEU: 0.4679\n",
            "Example 4 BLEU: 0.8204\n",
            "Example 5 BLEU: 0.6732\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5841\n",
            "Epoch 24 | Train Loss: 1.2374 | Val Loss: 2.1887 | BLEU: 0.5841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.4800\n",
            "Example 2 BLEU: 0.7080\n",
            "Example 3 BLEU: 0.3780\n",
            "Example 4 BLEU: 0.7982\n",
            "Example 5 BLEU: 0.5595\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5847\n",
            "Epoch 25 | Train Loss: 1.3231 | Val Loss: 2.3065 | BLEU: 0.5847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.6138\n",
            "Example 2 BLEU: 0.6414\n",
            "Example 3 BLEU: 0.4360\n",
            "Example 4 BLEU: 0.8880\n",
            "Example 5 BLEU: 0.1625\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5483\n",
            "Epoch 26 | Train Loss: 1.3028 | Val Loss: 2.3478 | BLEU: 0.5483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.5312\n",
            "Example 2 BLEU: 0.6677\n",
            "Example 3 BLEU: 0.4108\n",
            "Example 4 BLEU: 0.8192\n",
            "Example 5 BLEU: 0.1515\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5161\n",
            "Epoch 27 | Train Loss: 1.3266 | Val Loss: 2.2137 | BLEU: 0.5161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 1 BLEU: 0.6639\n",
            "Example 2 BLEU: 0.7565\n",
            "Example 3 BLEU: 0.5006\n",
            "Example 4 BLEU: 0.8100\n",
            "Example 5 BLEU: 0.1718\n",
            "\n",
            "Avg BLEU over 5 samples: 0.5806\n",
            "Epoch 28 | Train Loss: 1.2355 | Val Loss: 2.3721 | BLEU: 0.5806\n",
            " Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model(model, \"best_model.pt\")\n",
        "\n",
        "# Try inference\n",
        "test_row = val_df.iloc[0]\n",
        "src_tensor = torch.tensor(test_row['py_input_ids'], dtype=torch.long)\n",
        "predicted_tokens = beam_search(model, src_tensor)\n",
        "print(\"Predicted:\", \" \".join(predicted_tokens))\n",
        "print(\"Reference:\", \" \".join(test_row['cpp_tokens']))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BItTNhC_adLX",
        "outputId": "6f9622d0-f332-4f3c-f706-24274203a4f0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: maxChunksToSorted ( auto A ) { { , gcd , mx , mn = [ 0 ] * len ( A ) , [ 0 ] * len ( A ) , - 0 float ( inf \" ) for i , in enumerate num enumerate ( ) : mx = max ( mx , num ) ) [ i ] = mx for i in range ( len ( A A ) i 1 ) : = = ( mx , , [ i ] ) mx [ i ] = mn for in range ( len ( ( A A ) i 1 ) : : = min ( mn , [ i [ ] ) mx [ i ] = [ for in range ( len ( ( A A ) i 1 ) : if = [ i ] < = [ [ i + 1 ] return i + 1 }\n",
            "Reference: auto partitionDisjoint ( auto A ) { rMin , lMax , mx , mn = [ 0 ] * len ( A ) , [ 0 ] * len ( A ) , - float ( \" inf \" ) , float ( \" inf \" ) for i , num in enumerate ( A ) : mx = max ( mx , num ) lMax [ i ] = mx for i in range ( len ( A ) - 1 , - 1 , - 1 ) : mn = min ( mn , A [ i ] ) rMin [ i ] = mn for i in range ( len ( A ) - 1 ) : if lMax [ i ] < = rMin [ i + 1 ] : return i + 1 }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niWEDxT11Lpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}