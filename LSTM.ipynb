{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELzXHi22SMQ1"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6LHDjU4FRJ1a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('python_to_valid_cpp.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_icTvzJRagn"
      },
      "source": [
        "## Data Preprocesing using the Tree_sitter tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Tree-sitter tokenizer\n",
        "from tree_sitter import Language, Parser\n",
        "\n",
        "# Load precompiled language library (make sure it's already built)\n",
        "PY_LANGUAGE = Language(\"build/my-languages.dll\", \"python\")\n",
        "CPP_LANGUAGE = Language(\"build/my-languages.dll\", \"cpp\")\n",
        "\n",
        "def tree_sitter_tokenize(code: str, language: str = \"python\") -> list:\n",
        "    parser = Parser()\n",
        "    parser.set_language(PY_LANGUAGE if language == \"python\" else CPP_LANGUAGE)\n",
        "    tree = parser.parse(bytes(code, \"utf8\"))\n",
        "    root = tree.root_node\n",
        "\n",
        "    tokens = []\n",
        "    def extract_tokens(node):\n",
        "        if node.child_count == 0:\n",
        "            tokens.append(code[node.start_byte:node.end_byte])\n",
        "        for child in node.children:\n",
        "            extract_tokens(child)\n",
        "    extract_tokens(root)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AhbAKXKWRX8Y"
      },
      "outputs": [],
      "source": [
        "SPECIAL_TOKENS = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
        "\n",
        "# Wrapper to make tokenizer API consistent\n",
        "def tokenize_code(code, lang=\"python\"):\n",
        "    return tree_sitter_tokenize(code, language=lang)\n",
        "\n",
        "def build_vocab(token_lists, max_vocab_size=10000):\n",
        "    all_tokens = list(chain.from_iterable(token_lists))\n",
        "    token_counts = Counter(all_tokens)\n",
        "    most_common = token_counts.most_common(max_vocab_size - len(SPECIAL_TOKENS))\n",
        "    vocab = SPECIAL_TOKENS + [token for token, _ in most_common]\n",
        "    token_to_id = {token: idx for idx, token in enumerate(vocab)}\n",
        "    id_to_token = {idx: token for token, idx in token_to_id.items()}\n",
        "    return token_to_id, id_to_token\n",
        "\n",
        "def tokens_to_ids(tokens, token_to_id, add_sos=False, add_eos=False):\n",
        "    ids = [token_to_id.get(token, token_to_id['<unk>']) for token in tokens]\n",
        "    if add_sos:\n",
        "        ids = [token_to_id['<sos>']] + ids\n",
        "    if add_eos:\n",
        "        ids += [token_to_id['<eos>']]\n",
        "    return ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dmgP3pjRePY"
      },
      "source": [
        "### Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nOaRdXRwRhf0"
      },
      "outputs": [],
      "source": [
        "class CodeTranslationDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.encoder_inputs = df['py_tensor'].tolist()\n",
        "        self.decoder_inputs = df['cpp_in_tensor'].tolist()\n",
        "        self.decoder_outputs = df['cpp_out_tensor'].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoder_inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoder_inputs[idx], self.decoder_inputs[idx], self.decoder_outputs[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    enc_inputs, dec_inputs, dec_outputs = zip(*batch)\n",
        "    enc_inputs_pad = pad_sequence(enc_inputs, batch_first=True, padding_value=py_token_to_id['<pad>'])\n",
        "    dec_inputs_pad = pad_sequence(dec_inputs, batch_first=True, padding_value=cpp_token_to_id['<pad>'])\n",
        "    dec_outputs_pad = pad_sequence(dec_outputs, batch_first=True, padding_value=cpp_token_to_id['<pad>'])\n",
        "    return enc_inputs_pad, dec_inputs_pad, dec_outputs_pad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6CZF85rRmZS"
      },
      "source": [
        "### Attention-based LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZgQdgcgBRlpT"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hid_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        self.v = nn.Parameter(torch.rand(hid_dim))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.size(1)\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = torch.sum(self.v * energy, dim=2)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(hid_dim + emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.attn = Attention(hid_dim)\n",
        "\n",
        "    def forward(self, input, hidden, cell, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        a = self.attn(hidden[-1], encoder_outputs).unsqueeze(1)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, (hidden, cell) = self.lstm(rnn_input, (hidden, cell))\n",
        "        prediction = self.fc_out(torch.cat((output.squeeze(1), weighted.squeeze(1)), dim=1))\n",
        "        return prediction, hidden, cell\n",
        "\n",
        "\n",
        "class AttnEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(emb_dim, hid_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        return outputs, hidden, cell\n",
        "\n",
        "\n",
        "class AttnSeq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.embedding.num_embeddings\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
        "        encoder_outputs, hidden, cell = self.encoder(src)\n",
        "        input = trg[:, 0]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
        "            outputs[:, t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if torch.rand(1).item() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo8y0pgtUOvX"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aVDfqN72UZwQ"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def step(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "\n",
        "def train(model, dataloader, optimizer, criterion, clip, teacher_forcing_ratio=0.5):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for src, trg_in, trg_out in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        src, trg_in, trg_out = src.to(DEVICE), trg_in.to(DEVICE), trg_out.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Pass the teacher forcing ratio to the model\n",
        "        output = model(src, trg_in, teacher_forcing_ratio)\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg_out = trg_out[:, 1:].reshape(-1)\n",
        "        loss = criterion(output, trg_out)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        torch.cuda.empty_cache()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for src, trg_in, trg_out in dataloader:\n",
        "            src, trg_in, trg_out = src.to(DEVICE), trg_in.to(DEVICE), trg_out.to(DEVICE)\n",
        "            output = model(src, trg_in, teacher_forcing_ratio=0.0)\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[:, 1:].reshape(-1, output_dim)\n",
        "            trg_out = trg_out[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg_out)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGRFFuShZseB"
      },
      "source": [
        "### Beam Search & BLEU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "960B8g9MUZ6i"
      },
      "outputs": [],
      "source": [
        "def beam_search(model, src_tensor, beam_width=3, max_len=300):\n",
        "    model.eval()\n",
        "    src_tensor = src_tensor.unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    # Encode the source\n",
        "    encoder_outputs, hidden, cell = model.encoder(src_tensor)\n",
        "\n",
        "    # Start with <sos> token\n",
        "    sequences = [[[], 0.0, torch.tensor([cpp_token_to_id['<sos>']], device=DEVICE), hidden, cell]]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        all_candidates = []\n",
        "\n",
        "        for seq, score, last_token, hidden, cell in sequences:\n",
        "            with torch.no_grad():\n",
        "                output, hidden, cell = model.decoder(last_token, hidden, cell, encoder_outputs)\n",
        "\n",
        "            probs = torch.log_softmax(output, dim=1)\n",
        "            topk = torch.topk(probs, beam_width)\n",
        "\n",
        "            for i in range(beam_width):\n",
        "                token = topk.indices[0][i]\n",
        "                prob = topk.values[0][i].item()\n",
        "\n",
        "                candidate = [seq + [token.item()], score + prob, token.unsqueeze(0), hidden, cell]\n",
        "                all_candidates.append(candidate)\n",
        "\n",
        "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "        if all(seq[0][-1] == cpp_token_to_id['<eos>'] for seq in sequences):\n",
        "            break\n",
        "\n",
        "    return [cpp_id_to_token.get(idx, '<unk>') for idx in sequences[0][0] if idx != cpp_token_to_id['<eos>']]\n",
        "\n",
        "\n",
        "def compute_bleu(pred_tokens, ref_tokens):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    return sentence_bleu([ref_tokens], pred_tokens, smoothing_function=smoothie)\n",
        "\n",
        "def evaluate_bleu(model, val_df, num_samples=5):\n",
        "    total_bleu = 0\n",
        "    for i in range(min(num_samples, len(val_df))):\n",
        "        row = val_df.iloc[i]\n",
        "        src_tensor = torch.tensor(row['py_input_ids'], dtype=torch.long)\n",
        "        pred = beam_search(model, src_tensor)\n",
        "        ref = row['cpp_tokens']\n",
        "        bleu = compute_bleu(pred, ref)\n",
        "        total_bleu += bleu\n",
        "        print(f\"Example {i+1} BLEU: {bleu:.4f}\")\n",
        "    avg_bleu = total_bleu / num_samples\n",
        "    print(f\"\\nAvg BLEU over {num_samples} samples: {avg_bleu:.4f}\")\n",
        "    return avg_bleu\n",
        "\n",
        "def save_model(model, path=\"best_model.pt\"):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_model(model, path=\"best_model.pt\"):\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S96f5w3vaB_9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kPgME7nfaFoC"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"python_to_valid_cpp.csv\")\n",
        "\n",
        "# Use Tree-sitter tokenizer explicitly for each language\n",
        "df['py_tokens'] = df['code'].apply(lambda x: tokenize_code(x, lang=\"python\"))\n",
        "df['cpp_tokens'] = df['cpp_code'].apply(lambda x: tokenize_code(x, lang=\"cpp\"))\n",
        "\n",
        "# Build vocabularies\n",
        "py_token_to_id, py_id_to_token = build_vocab(df['py_tokens'])\n",
        "cpp_token_to_id, cpp_id_to_token = build_vocab(df['cpp_tokens'])\n",
        "\n",
        "# Convert tokens to input/output ID sequences\n",
        "df['py_input_ids'] = df['py_tokens'].apply(lambda tokens: tokens_to_ids(tokens, py_token_to_id))\n",
        "df['cpp_input_ids'] = df['cpp_tokens'].apply(lambda tokens: tokens_to_ids(tokens, cpp_token_to_id, add_sos=True))\n",
        "df['cpp_output_ids'] = df['cpp_tokens'].apply(lambda tokens: tokens_to_ids(tokens, cpp_token_to_id, add_eos=True))\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "df['py_tensor'] = df['py_input_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "df['cpp_in_tensor'] = df['cpp_input_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "df['cpp_out_tensor'] = df['cpp_output_ids'].apply(lambda x: torch.tensor(x, dtype=torch.long))\n",
        "\n",
        "# Filter out long sequences\n",
        "MAX_LEN = 300\n",
        "df = df[df['py_input_ids'].apply(len) <= MAX_LEN]\n",
        "df = df[df['cpp_input_ids'].apply(len) <= MAX_LEN]\n",
        "df = df[df['cpp_output_ids'].apply(len) <= MAX_LEN]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train-validation split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CtF1vOI6aR9H"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(CodeTranslationDataset(train_df), batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(CodeTranslationDataset(val_df), batch_size=1, shuffle=False, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2mg3jL8xaSHC"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INPUT_DIM = len(py_token_to_id)\n",
        "OUTPUT_DIM = len(cpp_token_to_id)\n",
        "EMB_DIM = 128\n",
        "HID_DIM = 256\n",
        "\n",
        "# Use the LSTM-based encoder and decoder defined earlier\n",
        "encoder = AttnEncoder(INPUT_DIM, EMB_DIM, HID_DIM).to(DEVICE)\n",
        "decoder = AttnDecoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(DEVICE)\n",
        "model = AttnSeq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=cpp_token_to_id['<pad>'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GL8HjLJVb1Tw"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRF3PJD-aXDb",
        "outputId": "268d019b-1160-45f6-edc6-c4fede0f0f4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.0264\n",
            "Example 2 BLEU: 0.0067\n",
            "Example 3 BLEU: 0.0308\n",
            "Example 4 BLEU: 0.0172\n",
            "Example 5 BLEU: 0.0074\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0177\n",
            "Epoch 1 | Train Loss: 4.3369 | Val Loss: 4.2380 | BLEU: 0.0177\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.0432\n",
            "Example 2 BLEU: 0.0317\n",
            "Example 3 BLEU: 0.0390\n",
            "Example 4 BLEU: 0.0122\n",
            "Example 5 BLEU: 0.0408\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0334\n",
            "Epoch 2 | Train Loss: 3.5952 | Val Loss: 3.9785 | BLEU: 0.0334\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.0587\n",
            "Example 2 BLEU: 0.0391\n",
            "Example 3 BLEU: 0.1107\n",
            "Example 4 BLEU: 0.0635\n",
            "Example 5 BLEU: 0.0568\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0657\n",
            "Epoch 3 | Train Loss: 3.1286 | Val Loss: 3.8210 | BLEU: 0.0657\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.0321\n",
            "Example 2 BLEU: 0.0554\n",
            "Example 3 BLEU: 0.0612\n",
            "Example 4 BLEU: 0.0647\n",
            "Example 5 BLEU: 0.0820\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0591\n",
            "Epoch 4 | Train Loss: 2.7764 | Val Loss: 3.7559 | BLEU: 0.0591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.0963\n",
            "Example 2 BLEU: 0.0752\n",
            "Example 3 BLEU: 0.0690\n",
            "Example 4 BLEU: 0.0837\n",
            "Example 5 BLEU: 0.0873\n",
            "\n",
            "Avg BLEU over 5 samples: 0.0823\n",
            "Epoch 5 | Train Loss: 2.4771 | Val Loss: 3.7515 | BLEU: 0.0823\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.1114\n",
            "Example 2 BLEU: 0.1220\n",
            "Example 3 BLEU: 0.0886\n",
            "Example 4 BLEU: 0.1045\n",
            "Example 5 BLEU: 0.2868\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1427\n",
            "Epoch 6 | Train Loss: 2.2656 | Val Loss: 3.7614 | BLEU: 0.1427\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.1044\n",
            "Example 2 BLEU: 0.1267\n",
            "Example 3 BLEU: 0.2625\n",
            "Example 4 BLEU: 0.1125\n",
            "Example 5 BLEU: 0.3317\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1876\n",
            "Epoch 7 | Train Loss: 2.0743 | Val Loss: 3.7730 | BLEU: 0.1876\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.2713\n",
            "Example 2 BLEU: 0.2021\n",
            "Example 3 BLEU: 0.0849\n",
            "Example 4 BLEU: 0.1253\n",
            "Example 5 BLEU: 0.2917\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1951\n",
            "Epoch 8 | Train Loss: 1.9072 | Val Loss: 3.7342 | BLEU: 0.1951\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.1876\n",
            "Example 2 BLEU: 0.0601\n",
            "Example 3 BLEU: 0.2036\n",
            "Example 4 BLEU: 0.0796\n",
            "Example 5 BLEU: 0.2405\n",
            "\n",
            "Avg BLEU over 5 samples: 0.1543\n",
            "Epoch 9 | Train Loss: 1.7901 | Val Loss: 3.8436 | BLEU: 0.1543\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.2551\n",
            "Example 2 BLEU: 0.1850\n",
            "Example 3 BLEU: 0.2704\n",
            "Example 4 BLEU: 0.1152\n",
            "Example 5 BLEU: 0.3128\n",
            "\n",
            "Avg BLEU over 5 samples: 0.2277\n",
            "Epoch 10 | Train Loss: 1.7041 | Val Loss: 3.7451 | BLEU: 0.2277\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.3892\n",
            "Example 2 BLEU: 0.1713\n",
            "Example 3 BLEU: 0.2396\n",
            "Example 4 BLEU: 0.3625\n",
            "Example 5 BLEU: 0.4914\n",
            "\n",
            "Avg BLEU over 5 samples: 0.3308\n",
            "Epoch 11 | Train Loss: 1.5646 | Val Loss: 3.8167 | BLEU: 0.3308\n",
            " Best model saved\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.2134\n",
            "Example 2 BLEU: 0.2949\n",
            "Example 3 BLEU: 0.3331\n",
            "Example 4 BLEU: 0.1528\n",
            "Example 5 BLEU: 0.4336\n",
            "\n",
            "Avg BLEU over 5 samples: 0.2856\n",
            "Epoch 12 | Train Loss: 1.4973 | Val Loss: 3.7422 | BLEU: 0.2856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1 BLEU: 0.3668\n",
            "Example 2 BLEU: 0.2618\n",
            "Example 3 BLEU: 0.1029\n",
            "Example 4 BLEU: 0.1617\n",
            "Example 5 BLEU: 0.5012\n",
            "\n",
            "Avg BLEU over 5 samples: 0.2789\n",
            "Epoch 13 | Train Loss: 1.4348 | Val Loss: 3.9821 | BLEU: 0.2789\n",
            " Early stopping triggered.\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 30\n",
        "CLIP = 1.0\n",
        "best_bleu = 0\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    teacher_forcing_ratio = 0.5  # (optional: decay this over epochs if you want)\n",
        "\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP, teacher_forcing_ratio)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "    bleu = evaluate_bleu(model, val_df, num_samples=5)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | BLEU: {bleu:.4f}\")\n",
        "\n",
        "    if bleu > best_bleu:\n",
        "        best_bleu = bleu\n",
        "        save_model(model, \"best_model.pt\")\n",
        "        print(\" Best model saved\")\n",
        "\n",
        "    early_stopper.step(val_loss)\n",
        "    if early_stopper.early_stop:\n",
        "        print(\" Early stopping triggered.\")\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BItTNhC_adLX",
        "outputId": "6f9622d0-f332-4f3c-f706-24274203a4f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\samue\\AppData\\Local\\Temp\\ipykernel_16692\\428696025.py:58: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted: removeElement ( auto A ) { \" , \" , mx , mn = [ 0 ] len ( A ) , [ 0 ] len len A ) , [ 0 ] len ( A ) , float ( \" inf ) ) i , i in ( enumerate A A ) : mx = max ( mx mx num , ) ) [ i ] i for in range ( len ( A ) - 1 ) : if in [ i ] <= <= [ i + <= <= [ i + <= : return i + 1 }\n",
            "Reference: auto partitionDisjoint ( auto A ) { rMin , lMax , mx , mn = [ 0 ] * len ( A ) , [ 0 ] * len ( A ) , - float ( \" inf \" ) , float ( \" inf \" ) for i , num in enumerate ( A ) : mx = max ( mx , num ) lMax [ i ] = mx for i in range ( len ( A ) - 1 , -1 , -1 ) : mn = min ( mn , A [ i ] ) rMin [ i ] = mn for i in range ( len ( A ) - 1 ) : if lMax [ i ] <= rMin [ i + 1 ] : return i + 1 } \n"
          ]
        }
      ],
      "source": [
        "load_model(model, \"best_model.pt\")\n",
        "\n",
        "# Try inference\n",
        "test_row = val_df.iloc[0]\n",
        "src_tensor = torch.tensor(test_row['py_input_ids'], dtype=torch.long)\n",
        "predicted_tokens = beam_search(model, src_tensor)\n",
        "print(\"Predicted:\", \" \".join(predicted_tokens))\n",
        "print(\"Reference:\", \" \".join(test_row['cpp_tokens']))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml2_final",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
